{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jogo Connect Four com Inteligência Artificial: Árvores de Decisão e MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizado pelos alunos:\n",
    "- Rita Moreira (202303885);\n",
    "- Pedro Gilvaia (202306975);\n",
    "- Gonçalo Correia (202208527)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introdução  \n",
    "2. Descrição do problema  \n",
    "   **2.1.**  Implementação do jogo  \n",
    "3. Metodologia e sua implementação  \n",
    "   **3.1.**  Monte Carlo Tree Search (MCTS)  \n",
    "   **3.2.**  Geração do Dataset  \n",
    "   **3.3.**  Árvores de Decisão  \n",
    "4. Integração no Jogo  \n",
    "5. Resultados  \n",
    "   **5.1.**  Runs  \n",
    "      **5.1.1.**  Jogador vs. MCTS  \n",
    "      **5.1.2.**  Jogador vs. Árvore de Decisão  \n",
    "      **5.1.3.**  MCTS vs. Árvore de Decisão  \n",
    "6. Discussão de Resultados  \n",
    "   **6.1.**  Desempenho do MCTS  \n",
    "   **6.2.**  Frequência de Jogadas do MCTS  \n",
    "   **6.3.**  Impacto do Alpha  \n",
    "   **6.4.**  Forças e limitações do algoritmo Monte Carlo Tree Search (MCTS)  \n",
    "   **6.5.**  Desempenho da Árvore de Decisão com algoritmo ID3  \n",
    "   **6.6.**  Relação entre acurácia, profundidade e tempo de previsão da árvore de decisão  \n",
    "   **6.7.**  Forças e limitações do algoritmo Iterative Dichotomiser 3 (ID3)  \n",
    "   **6.8.**  Comparação Geral  \n",
    "   **6.9.**  Sugestões de Extensões Futuras  \n",
    "7. Conclusão  \n",
    "8. Referências  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto implementa e compara duas abordagens de Inteligência Artificial aplicadas ao jogo Connect Four:\n",
    "1. Uma baseada no algoritmo **ID3** (árvore de decisão supervisionada), treinada a partir de exemplos jogados;\n",
    "2. Outra baseada em **Monte Carlo Tree Search (MCTS)**, uma estratégia de procura não supervisionada amplamente utilizada em jogos como Go e Xadrez.\n",
    "\n",
    "O objetivo é compreender o funcionamento, vantagens e limitações de cada abordagem na resolução de jogos com estados complexos e decisões sequenciais.\n",
    "\n",
    "Este notebook inclui:\n",
    "- Uma explicação dos fundamentos teóricos de ID3 e MCTS;\n",
    "- Implementações completas de ambas as técnicas aplicadas ao Connect Four;\n",
    "- Experimentos entre jogador humano e IA;\n",
    "- Discussão sobre o impacto dos parâmetros e do desempenho das IAs;\n",
    "- Conclusões sobre qual abordagem é mais adequada em diferentes cenários.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descrição do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Quatro em Linha é um jogo de estratégia de dois jogadores. São usadas 42 peças, 21 para cada jogador, e um tabuleiro vertical com 7 colunas e 6 filas. A cada jogada, o jogador atual \"deixa cair\" a sua peça numa coluna à sua escolha, desde que não esteja cheia. Esta cai na linha disponível. Um jogador ganha quando 4 das suas peças formarem uma linha horizontal, vertical ou diagonal consecutiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Implementação do Jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo segue-se a implementação das funcionalidades do jogo (connected_four.py). Mais tarde, será apresentada a implementação do jogo em si (game.py), que utiliza todos os códigos trabalhados no projeto (connected_four.py, mcts.py e decision_tree_builder.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __connected_four.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `GameMeta` funciona como um container de constantes e parâmetros globais que descrevem as regras básicas e convenções do jogo Connect Four na sua implementação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameMeta:\n",
    "    # dicionário que mapeia nomes de jogador para valores usados no jogo\n",
    "    PLAYERS = {'none': 0, 'one': 1, 'two': 2} \n",
    "    # dicionário que mapeia resultados possíveis de uma partida\n",
    "    OUTCOMES = {'none': 0, 'one': 1, 'two': 2, 'draw': 3}\n",
    "    # constante que representa \"infinito\" em pontuações ou limites\n",
    "    INF = float('inf')\n",
    "    # definição do tamanho do tabuleiro (ROWS x COLS)\n",
    "    ROWS = 6\n",
    "    COLS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `MCTSMeta` define o coeficiente de exploração (c). Tem como papel balancear o teste de ramos menos visitados para descobrir se possuem bons resultados (exploit) e a escolha do ramo com maior valor médio $\\frac{Q}{N}$. Um c grande amplia a exploração de nós (explore) e um c pequeno prioriza o valor $\\frac{Q}{N}$ (exploit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSMeta:\n",
    "    EXPLORATION = 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `ConnectState` representa o estado de um jogo. A função `__init__` é um construtor da classe, e inicializa o tabuleiro, o jogador atual, a altura de cada coluna e a última jogada feita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possui atributos como:\n",
    "- `board`: matriz 6x7 com valores 0 (vazio), 1(jogador 1) e 2 (jogador 2);\n",
    "- `to_play`: identificador do jogador que jogará a seguir;\n",
    "- `height`: lista de índices da próxima linha livre em cada coluna\n",
    "- `last_played`: par [linha, coluna] da última jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectState:\n",
    "    def __init__(self):\n",
    "        # Inicializa o tabuleiro com zeros (vazio)\n",
    "        self.board = [[0] * GameMeta.COLS for _ in range(GameMeta.ROWS)]\n",
    "        # Inicializa o jogador atual como 'one' (1)\n",
    "        self.to_play = GameMeta.PLAYERS['one']\n",
    "        # Inicializa a altura de cada coluna como o número de linhas menos 1 (posição inicial)\n",
    "        self.height = [GameMeta.ROWS - 1] * GameMeta.COLS\n",
    "        # Inicializa a lista de ações jogadas como nula\n",
    "        self.last_played = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `get_board` retorna uma cópia do tabuleiro atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board(self):\n",
    "        return deepcopy(self.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `move` executa um movimento numa coluna específica e atualiza o estado de jogo. Se a coluna estiver cheia, surge um `ValueError`. Possui como parâmetro a coluna onde o jogador quer jogar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(self, col):\n",
    "        # Verifica se a coluna está cheia\n",
    "        if self.height[col] < 0:\n",
    "            raise ValueError(f\"Coluna {col} já está cheia!\")  # Retorna ValueError (permite que jogador tente novamente)\n",
    "        self.board[self.height[col]][col] = self.to_play # Atualiza a posição do jogador no tabuleiro: coloca código de jogador na coluna escolhida\n",
    "        self.last_played = [self.height[col], col] # Atualiza a última jogada\n",
    "        self.height[col] -= 1 # Atualiza a altura da coluna (próxima linha disponível)\n",
    "        # Alterna entre os jogadores\n",
    "        self.to_play = GameMeta.PLAYERS['two'] if self.to_play == GameMeta.PLAYERS['one'] else GameMeta.PLAYERS['one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `get_legal_moves` retorna uma lista dos índices das colunas onde ainda é possível jogar, isto é, que não estejam cheias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legal_moves(self):\n",
    "        # Obtém as colunas disponíveis para jogar: onde o valor é 0\n",
    "        return [col for col in range(GameMeta.COLS) if self.board[0][col] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `check_win` verifica se o jogador atual venceu. Se sim, retorna o código do mesmo (1 ou 2, dependendo do jogador). Se não houver vitória, retorna 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win(self):\n",
    "        # se não existir jogada anterior, não há vencedor (retorna 0)\n",
    "        # se houver jogada anterior, verifica se o jogador atual ganhou (row->0, col->1) usando a função check_win_from\n",
    "        if len(self.last_played) > 0 and self.check_win_from(self.last_played[0], self.last_played[1]):\n",
    "            return self.board[self.last_played[0]][self.last_played[1]]\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `check_win_from` verifica se há \"quatro em linha\" a partir da posição (row, col) em todas as direções: horizontal, vertical, diagonal principal e diagonal secundária. Se sim, retorna True. Caso contrário, retorna False. Tem como parâmetros a linha (`row`) e a coluna (`col`) da última jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win_from(self, row, col):\n",
    "        player = self.board[row][col] # jogador atual (1 ou 2)\n",
    "        consecutive = 1 # acumular número de jogadas consecutivas do jogador atual\n",
    "        # verificar vertical\n",
    "        tmprow = row # linha atual (temp)\n",
    "        # enquanto a linha atual + 1 estiver dentro do tabuleiro\n",
    "        # e (linha atual + 1 , coluna) tiver o codigo do jogador atual\n",
    "        while tmprow + 1 < GameMeta.ROWS and self.board[tmprow + 1][col] == player: \n",
    "            consecutive += 1 #acumulador aumenta\n",
    "            tmprow += 1 #linha atual aumenta\n",
    "        tmprow = row #mesmo processo mas para o lado oposto (para baixo)\n",
    "        while tmprow - 1 >= 0 and self.board[tmprow - 1][col] == player:\n",
    "            consecutive += 1\n",
    "            tmprow -= 1\n",
    "        # se o número de jogadas consecutivas for maior ou igual a 4, retorna True (quatro em linha vertical)\n",
    "        if consecutive >= 4:\n",
    "            return True\n",
    "\n",
    "        # verifica horizontal (mesmo processo mas para várias colunas na mesma linha)\n",
    "        consecutive = 1\n",
    "        tmpcol = col\n",
    "        while tmpcol + 1 < GameMeta.COLS and self.board[row][tmpcol + 1] == player:\n",
    "            consecutive += 1\n",
    "            tmpcol += 1\n",
    "        tmpcol = col\n",
    "        while tmpcol - 1 >= 0 and self.board[row][tmpcol - 1] == player:\n",
    "            consecutive += 1\n",
    "            tmpcol -= 1\n",
    "        # se o número de jogadas consecutivas for maior ou igual a 4, retorna True (quatro em linha horizontal)\n",
    "        if consecutive >= 4:\n",
    "            return True\n",
    "\n",
    "        # verifica diagonal (mudanças de linha e coluna na diagonal principal)\n",
    "        consecutive = 1\n",
    "        tmprow = row\n",
    "        tmpcol = col\n",
    "        # diagonal principal a subir\n",
    "        while tmprow + 1 < GameMeta.ROWS and tmpcol + 1 < GameMeta.COLS and self.board[tmprow + 1][tmpcol + 1] == player:\n",
    "            consecutive += 1\n",
    "            tmprow += 1\n",
    "            tmpcol += 1\n",
    "        tmprow = row\n",
    "        tmpcol = col\n",
    "        #diagonal principal a descer\n",
    "        while tmprow - 1 >= 0 and tmpcol - 1 >= 0 and self.board[tmprow - 1][tmpcol - 1] == player:\n",
    "            consecutive += 1\n",
    "            tmprow -= 1\n",
    "            tmpcol -= 1\n",
    "\n",
    "        if consecutive >= 4:\n",
    "            return True\n",
    "\n",
    "        # verifica anti-diagonal / diagonal secundária (mesmo processo mas para a diagonal secundária)\n",
    "        consecutive = 1\n",
    "        tmprow = row\n",
    "        tmpcol = col\n",
    "        # diagonal secundária a subir\n",
    "        while tmprow + 1 < GameMeta.ROWS and tmpcol - 1 >= 0 and self.board[tmprow + 1][tmpcol - 1] == player:\n",
    "            consecutive += 1\n",
    "            tmprow += 1\n",
    "            tmpcol -= 1\n",
    "        tmprow = row\n",
    "        tmpcol = col\n",
    "        # diagonal secundária a descer\n",
    "        while tmprow - 1 >= 0 and tmpcol + 1 < GameMeta.COLS and self.board[tmprow - 1][tmpcol + 1] == player:\n",
    "            consecutive += 1\n",
    "            tmprow -= 1\n",
    "            tmpcol += 1\n",
    "\n",
    "        if consecutive >= 4:\n",
    "            return True\n",
    "        # se não houver quatro em linha, retorna False\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `game_over` verifica se o jogo acabou, retornando um valor booleano consoante o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_over(self):\n",
    "        # verifica se o jogo terminou: usa a função check_win para verificar se há um vencedor\n",
    "        # ou se não há mais jogadas disponíveis (todas as colunas cheias), o que dá um empate\n",
    "        return self.check_win() or len(self.get_legal_moves()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `get_outcome` retorna o código de resultado (outcome) da partida. Se for vitória retorna 1 ou 2, dependendo do jogador vencedor. Se for empate retorna 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(self):\n",
    "        # se não houver mais jogadas disponíveis e não houver vencedor, retorna empate\n",
    "        if len(self.get_legal_moves()) == 0 and self.check_win() == 0:\n",
    "            return GameMeta.OUTCOMES['draw'] # 3\n",
    "        # se houver vencedor, retorna o jogador vencedor (código 1 ou 2)\n",
    "        return GameMeta.OUTCOMES['one'] if self.check_win() == GameMeta.PLAYERS['one'] else GameMeta.OUTCOMES['two']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, a função `print` exibe o tabuleiro no terminal e substitui o número que está na matriz (tabuleiro) pela peça de jogo ou espaço vazio:\n",
    "- ' ' (espaço) substitui o 0;\n",
    "- X substitui o 1;\n",
    "- O substitui o 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print(self):\n",
    "    print('=============================')\n",
    "\n",
    "    for row in range(GameMeta.ROWS):\n",
    "        for col in range(GameMeta.COLS):\n",
    "            # imprime o tabuleiro com os códigos dos jogadores (1 ou 2) ou vazio (0)\n",
    "            print('| {} '.format('X' if self.board[row][col] == 1 else 'O' if self.board[row][col] == 2 else ' '), end='')\n",
    "        print('|')\n",
    "\n",
    "    print('=============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metodologia e sua implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Monte Carlo Tree Search (MCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O MCTS é um algoritmo de busca adversarial que leva em consideração as alterações de estado causadas por um adversário nas etapas subsequentes. A sua implementação utiliza o critério Upper Confidence Bound (UCT) para avaliar cada ramo de uma árvore, de fórmula:\n",
    "$$\n",
    "UCT = \\frac{Q}{N} + c\\sqrt{\\frac{In{N_{parent}}}{N}}\n",
    "$$\n",
    "O MCTS tem quatro fases:\n",
    "- Seleção: Começa na raiz e, em cada nó, escolhe o filho que maximiza o UCT até atingir um nó ainda não totalmente expandido;\n",
    "- Expansão:  A partir do nó selecionado, gera um dos estados-filho ainda não representados na árvore, adicionando-o como novo nó;\n",
    "- Simulação: A partir desse nó recém-criado, executa um jogo até ao fim (playout), usando uma política aleatória ou heurística, obtendo um resultado (vitória/derrota);\n",
    "- Retropropagação (Backpropagation): Propaga o resultado da simulação de volta à raiz, atualizando em cada nó visitado. Nesses nós, a contagem de visitas aumenta 1 valor e contagem de vitórias aumenta o valor do resultado (0 se perdeu, 1 se ganhou).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __mcts.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time # mede tempo de execução na simulação\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "from connected_four import ConnectState, GameMeta, MCTSMeta  #inicializa estado, jogo e mcts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe Node representa um nó de uma árvore de pesquisa Monte Carlo. A função `__init__` inicializa um nó e seus atributos:\n",
    "- `move`: jogada que levou ao nó atual;\n",
    "- `parent`: nó pai da árvore (a razi tem parent=None);\n",
    "- `N`: número de visitas;\n",
    "- `Q`: Soma das recompensas (vitórias) obtidas deste nó;\n",
    "- `children`: mapeia jogadas para nós-filho;\n",
    "- `outcome`: estado de resultado no nó (0=nenhum, 1=jogador1, 2=jogador2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, move, parent):\n",
    "        self.move = move\n",
    "        self.parent = parent\n",
    "        self.N = 0 #começa em zero\n",
    "        self.Q = 0 #começa em zero\n",
    "        self.children = {} #começa vazia\n",
    "        self.outcome = GameMeta.PLAYERS['none'] #começa em zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `add_children` adiciona nós-filho a partir de um dicionário (parâmetro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_children(self, children: dict) -> None:\n",
    "        for child in children:\n",
    "            #para cada nó filho, adiciona-o ao dicionário de filhos\n",
    "            self.children[child.move] = child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `get_exploration` calcula dinamicamente e retorna o coeficiente da exploração `c` para UCT. Baseia-se no número de visitas do nó pai e o valor diminui consoante a raiz quadrada desse número, levando a uma exploração maior no início e mais leve no final. Esta função aplica uma penalização logarítmica ao valor de C, reduzindo a exploração ao longo do tempo (annealing).\n",
    "$$ \\text{Exploration}(N) = \\frac{c_0}{1 + \\alpha \\cdot \\log(1 + N)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exploration(self) -> float:\n",
    "        c0 = MCTSMeta.EXPLORATION #1.4\n",
    "        if self.parent is not None:    #se nó pai não for nulo\n",
    "            root_visits = self.parent.N  #número de visitas do nó pai\n",
    "            alpha = 0.2 # fator de decaimento  (annealing)\n",
    "            return c0 / (1 +  alpha * math.log(1 + root_visits))\n",
    "        return c0 #se nó pai for nulo, retorna constante de exploração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `value` calcula e retorna o valor UCT do nó para a seleção. Utiliza como parâmetro o coeficiente inicial de exploração: 1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def value(self, explore: float = MCTSMeta.EXPLORATION):\n",
    "    if self.N == 0: # se não houver visitas, não há valor\n",
    "        return GameMeta.INF # forçar exploração de nós não visitados\n",
    "    else: #dynamic c\n",
    "        c_now = self.get_exploration() # calcula o valor de exploração atual\n",
    "        return self.Q / self.N + c_now * math.sqrt(math.log(self.parent.N) / self.N) # upper confidence bound (UCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe MCTS implementa o algoritmo para o Connected Four. A função `__init__` inicializa o MCTS com um estado inicial, que provem da classe ConnectedState.  Tem como atributos:\n",
    "- `root_state`: estado de jogo na raiz;\n",
    "- `root`: nó raiz da árvore de busca;\n",
    "- `run_time`: tempo gasto na última pesquisa (segundos de CPU);\n",
    "- `num_rollouts`: número de simulações executadas na última pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, state=ConnectState()):\n",
    "        self.root_state = deepcopy(state) # cópia do estado inicial\n",
    "        self.root = Node(None, None) #incializa nó raiz nulo\n",
    "        self.run_time = 0 #inicializa tempo de execução em zero\n",
    "        self.node_count = 0 #inicializa contagem de nós em zero\n",
    "        self.num_rollouts = 0 #inicializa número de simulações em zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira fase do MCTS é a seleção, representada pela função `select_node`. Esta seleciona um nó a ser expandido com base no UCT, até que um nó não visitado seja encontrado ou o jogo acabe. Retorna um tuplo, com o nó selecionado e o estado de jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_node(self) -> tuple:\n",
    "        node = self.root # nó raiz\n",
    "        state = deepcopy(self.root_state) # cópia do estado inicial\n",
    "\n",
    "        # Se o nó não tiver filhos, expande-o\n",
    "        while len(node.children) != 0:\n",
    "            # escolher o filho com maior valor UCT\n",
    "            children = node.children.values() # lista de filhos\n",
    "            max_value = max(children, key=lambda n: n.value()).value() # calcula o valor máximo entre os filhos\n",
    "            max_nodes = [n for n in children if n.value() == max_value] # filtra os filhos com o valor máximo\n",
    "\n",
    "            node = random.choice(max_nodes) # escolhe um nó aleatório entre os filhos com o valor máximo\n",
    "            state.move(node.move) # move o estado para o nó escolhido\n",
    "\n",
    "            if node.N == 0: # se o nó não tiver visitas, não há mais filhos a explorar\n",
    "                return node, state # retorna o nó e o estado\n",
    "        # se o nó não for terminal, expande-o\n",
    "        if self.expand(node, state):\n",
    "            node = random.choice(list(node.children.values())) # escolhe um nó filho aleatório\n",
    "            state.move(node.move) # move o estado para o nó filho escolhido\n",
    "\n",
    "        return node, state # retorna o nó e o estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A segunda fase é a expansão. A função `expand` cria filhos para o nó pai com base nas jogadas disponíveis. Se o estado for terminal, i.e., não houver expansão possível, retorna False. Tem como parâmetros:\n",
    "- `parent` (Nó): nó pai a ser expandido;\n",
    "- `state` (ConnectState): estado atual do jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(self, parent: Node, state: ConnectState) -> bool:\n",
    "        if state.game_over(): # se o jogo estiver terminado, não há mais jogadas possíveis\n",
    "            return False\n",
    "        #  lista de filhos do nó pai com base nas jogadas diponíveis\n",
    "        children = [Node(move, parent) for move in state.get_legal_moves()]\n",
    "        parent.add_children(children)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A terceira fase é a de simulação. A função correspondente, `roll_out`, joga aleatoriamente até ao fim do jogo e retorna o resultado do mesmo. Utiliza como argumento o estado do jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_out(self, state: ConnectState) -> int:\n",
    "        while not state.game_over(): # enquanto o jogo não terminar\n",
    "            moves = state.get_legal_moves() # lista de jogadas disponíveis\n",
    "            player = state.to_play # jogador atual\n",
    "            opp = 3 - player # jogador adversário (1 ou 2)\n",
    "            # Vitória imediata\n",
    "            for m in moves:\n",
    "                s2 = deepcopy(state) # cópia do estado\n",
    "                s2.move(m) # move o estado para a jogada escolhida\n",
    "                if s2.game_over() and s2.get_outcome() == player: # se o jogo terminar e o jogador atual vencer\n",
    "                    state.move(m) # move o estado para a jogada escolhida\n",
    "                    break \n",
    "            else:\n",
    "                # Bloqueio de ameaças adversárias\n",
    "                blocked = False # inicializa bloqueio como falso\n",
    "                for m in moves:\n",
    "                    s2 = deepcopy(state) # cópia do estado\n",
    "                    s2.move(m) # move o estado para a jogada escolhida\n",
    "                    for m2 in s2.get_legal_moves(): # lista de jogadas disponíveis\n",
    "                        s3 = deepcopy(s2) # cópia do estado\n",
    "                        s3.move(m2) # move o estado para a jogada escolhida\n",
    "                        if s3.game_over() and s3.get_outcome() == opp: # se o jogo terminar e o jogador adversário vencer\n",
    "                            state.move(m) # move o estado para a jogada escolhida\n",
    "                            blocked = True # bloqueia a jogada\n",
    "                            break\n",
    "                    if blocked: # se bloqueio for verdadeiro, sai do loop\n",
    "                        break\n",
    "                if not blocked: # se não houver bloqueio, joga aleatoriamente\n",
    "                    state.move(random.choice(moves))\n",
    "\n",
    "        return state.get_outcome() # retorna o resultado do jogo (vencedor ou empate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A última fase é a de Backpropagation (retropropagação). Tem como função `back_propagate`, que atualiza os valores de `N` e `Q` dos nós visitados. Tem como parâmetros:\n",
    "- `node` (Nó): nó onde terminou a simulação;\n",
    "- `turn` (int): jogador que fez a última jogada;\n",
    "- `outcome` (int): resultado do jogo (1,2 ou 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(self, node: Node, turn: int, outcome: int) -> None:\n",
    "        #recompensa relativa ao jogador 'turn'\n",
    "        reward = 0 if outcome == turn else 1 # se o jogador atual ganhar (turn) a recomepnsa é 1, caso contrário é 0\n",
    "\n",
    "        while node is not None:\n",
    "            node.N += 1 # incrementa o número de visitas dos nós visitados\n",
    "            node.Q += reward # incrementa a recompensa acumulada \n",
    "            node = node.parent # sobe na árvore\n",
    "            if outcome == GameMeta.OUTCOMES['draw']: # empate\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 1 - reward # inverte a recompensa (se o jogador atual ganhar, o adversário perde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para executar simulações do MCTS por um tempo limitado é usada a função `search`. Executa o MCTS por um limite de tempo.\n",
    "\n",
    "Args: time_limit (int): Tempo máximo (em segundos de CPU) para realizar simulações.\n",
    "\n",
    "Após o fim do tempo, self.num_rollouts e self.run_time ficam disponíveis com o número de rollouts realizados e o tempo efetivo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(self, time_limit: int):\n",
    "        start_time = time.process_time() # inicia o tempo de execução (limite)\n",
    "\n",
    "        num_rollouts = 0 # número de simulações\n",
    "        # enquanto o tempo de execução - o tempo inicial for menor que o limite\n",
    "        while time.process_time() - start_time < time_limit: \n",
    "            node, state = self.select_node() # seleciona o nó e o estado\n",
    "            outcome = self.roll_out(state) # simula o jogo até o fim\n",
    "            self.back_propagate(node, state.to_play, outcome) # atualiza os nós visitados\n",
    "            num_rollouts += 1 # incrementa o número de simulações\n",
    "\n",
    "        run_time = time.process_time() - start_time # calcula o tempo de execução\n",
    "        self.run_time = run_time # atualiza o tempo de execução\n",
    "        self.num_rollouts = num_rollouts # atualiza o número de simulações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `best_move` devolve a jogada mais promissora com base nas estatísticas do MCTS. Seleciona o filho da raiz com maior número de visitas (exploração intensiva), assumindo que mais visitas indicam maior confiança no resultado esperado.\n",
    "Returna a coluna correspondente à jogada selecionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(self):\n",
    "        if self.root_state.game_over(): # se o jogo estiver terminado, não há jogadas possíveis\n",
    "            return -1\n",
    "        # valor máximo entre os filhos do nó raiz\n",
    "        max_value = max(self.root.children.values(), key=lambda n: n.N).N\n",
    "        # filtra os filhos com o valor máximo\n",
    "        max_nodes = [n for n in self.root.children.values() if n.N == max_value]\n",
    "        # escolhe um nó filho aleatório entre os filhos com o valor máximo\n",
    "        best_child = random.choice(max_nodes)\n",
    "\n",
    "        return best_child.move # retorna a jogada escolhida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a raiz ser atualizada, é usada a função `move`, de parâmetro a coluna onde o jogador jogou (`move`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(self, move):\n",
    "        if move in self.root.children: # se a jogada já estiver na árvore\n",
    "            self.root_state.move(move) # move o estado para a jogada escolhida\n",
    "            self.root = self.root.children[move] # nó filho correspondente\n",
    "            return\n",
    "\n",
    "        self.root_state.move(move) # move o estado para a jogada escolhida\n",
    "        self.root = Node(None, None) # nó raiz nulo (inicializa nova árvore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, a função `statistics` retorna as estatísticas da última pesquisa:\n",
    "- o número de simulações feitas;\n",
    "- o tempo de CPU gasto nas mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(self) -> tuple:\n",
    "    return self.num_rollouts, self.run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Geração do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o algoritmo MCTS, foi gerado um dataset para treinar uma árvore de decisão, abordada de seguida. Este código simula múltiplas partidas de Connect Four usando o MCTS para gerar um conjunto de exemplos (estado, movimento) que servirão de treino para a árvore de decisão ID3. Cada linha do dataset contém 42 atributos (o tabuleiro achatado) seguidos da coluna escolhida pelo MCTS como 'move'. O dataset final (mcts_dataset.csv) tem 27118 linhas e 43 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mcts import MCTS \n",
    "from connected_four import ConnectState, GameMeta, MCTSMeta # inicializa estado, jogo e mcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `save_dataset` recebe a lista de tuplos `dataset` e o nome do ficheiro de saída, e salva-a como um ficheiro CSV com cabeçalho. O CSV gerado terá colunas 's0',...,'s41' e 'move'. O CSV gerado terá colunas 's0'...'s41' e 'move'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, filename='mcts_dataset.csv'):\n",
    "    with open(filename, 'w') as f:\n",
    "        # Cabeçalho com 42 features e o rótulo move\n",
    "        f.write(','.join([f's{i}' for i in range(42)]) + ',move\\n')\n",
    "        for state, move in dataset: # para cada estado e jogada no dataset\n",
    "            f.write(','.join(map(str, state)) + f',{move}\\n') # escreve no arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `generate_mcts_dataset` gera um dataset de pares (estados, movimento) usando o MCTS. Tem como parâmetro o número de partidas a simular (`num_games`) e retorna uma lista de tuplos (`board_flat`, `move`). Cada estado `board_flat` é uma lista de 42 inteiros representando o tabuleiro, seguido de `move` (coluna escolhida pelo MCTS). O MCTS recebe um tempo de busca variável: 3 segundos por jogada inicial e, após 10 jogadas, passa a 1.5 segundos. A função salva o dataset parcialmente a cada 10 jogos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcts_dataset(num_games=1000): # gera dataset de jogadas\n",
    "    dataset = [] # lista para armazenar os dados\n",
    "\n",
    "    for game_idx in range(num_games): # loop para cada jogo\n",
    "        print(f\"\\n🎮 Jogo {game_idx + 1} de {num_games}\")\n",
    "        state = ConnectState() # inicializa o estado do jogo\n",
    "        mcts = MCTS(state) # inicializa o MCTS\n",
    "        total_moves = 0  # contador de jogadas\n",
    "        mcts.search(time_limit=3)  # Tempo inicial para exploração mais profunda\n",
    "\n",
    "        while not state.game_over(): # enquanto o jogo não terminar\n",
    "            legal_moves = state.get_legal_moves() # lista de jogadas disponíveis\n",
    "            move = mcts.best_move() # jogada escolhida pelo MCTS\n",
    "            # Verifica e corrige movimento ilegal, se houver\n",
    "            if move not in legal_moves: # se a jogada não for válida\n",
    "                print(f\"[!] Movimento ilegal sugerido: {move}\")\n",
    "                move = random.choice(legal_moves) # escolhe uma jogada aleatória válida\n",
    "\n",
    "            try:\n",
    "                 # salva o estado atual do tabuleiro e a jogada\n",
    "                board_flat = [cell for row in state.get_board() for cell in row]\n",
    "                dataset.append((board_flat, move)) # adiciona ao dataset\n",
    "                # Aplica jogada no estado e no MCTS\n",
    "                state.move(move)\n",
    "                mcts.move(move)\n",
    "                total_moves += 1 # incrementa o contador de jogadas\n",
    "                # Ajuste de tempo por jogada após 10 movimentos\n",
    "                if not state.game_over():\n",
    "                    time_limit = 3 if total_moves < 10 else 1.5 # ajusta o tempo de execução\n",
    "                    mcts.search(time_limit=time_limit) # reinicia a busca\n",
    "\n",
    "            except ValueError as e: # se houver erro de movimento\n",
    "                print(f\"[Erro] Movimento inválido: {e}\")\n",
    "                break\n",
    "        # n´umero de jogadas totais\n",
    "        print(f\"✔️ Jogo {game_idx + 1} concluído — total de jogadas salvas: {len(dataset)}\")\n",
    "\n",
    "        # Salvamento parcial a cada 10 jogos\n",
    "        if (game_idx + 1) % 10 == 0:\n",
    "            save_dataset(dataset, filename='mcts_dataset_parcial.csv')\n",
    "            print(f\"💾 Dataset parcial salvo com {len(dataset)} jogadas.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, é possível fazer execução direta do gerador e salvar o dataset final. Neste caso foram escolhidos 1000 jogos, para ter boas informações e a árvore de decisão ser robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração e salvamento\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = generate_mcts_dataset(num_games=1000)\n",
    "    save_dataset(dataset) # salva o dataset final\n",
    "    print(f\"\\n✅ Dataset final salvo com {len(dataset)} exemplos!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Árvores de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o segundo método, foi utilizado um dataset (`iris.csv`) para testar (\"warm-up\") o algoritmo ID3. É um dataset mais pequeno, de contexto diferente, que tem como tarefa gerar/treinar uma árvore de decisão que, dadas quatro características (comprimento e largura da pétala, comprimento e largura da sépala), determine a que classe cada planta pertence (Iris setosa, Iris virginica ou Iris versicolor).\n",
    "Após esse teste, o objetivo é gerar uma árvore de decisão associada à implementação do algoritmo MCTS. É gerado um conjunto de pares ($state_{i}, move_{i}$), em que $state_{i}$ é o estado corrente do jogo e $move_{i}$ é o próximo movimento sugerido pelo algoritmo. Com esse dataset (`mcts_dataset.csv`), é treinada uma árvore de decisão usando o algoritmo ID3 (Iterative Dichotomiser 3), de forma a que, dado um estado de jogo, a árvore escolha o próximo movimento.\n",
    "Abaixo serão apresentadas os ficheiros decision_tree_builder.py, que implementa o algoritmo ID3, e `iris_test.py`, que aplica esse algoritmo no seu dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __decision_tree_builder.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle # exporta árvore\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe Node representa um nó numa árvore de decisão ID3. A função `__init__` inicializa o nó da árvore e tem como atributos:\n",
    "- `feature`: nome ou índice da feature usada para dividir neste nó (None se folha);\n",
    "- `children`: mapeamento do valor de feature para nós-filho;\n",
    "- `label`: Rótulo da classe se este nó for folha (None caso contrário)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, children=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.children = children if children is not None else {}\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `entropy` calcula e retorna a entropia de Shannon de um vetor/série de rótulos `y` (parâmetro). A entropia pode ser calculada usando a fórmula:\n",
    "$$ H(y) = -\\sum_{i} p_i \\cdot \\log_2(p_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    counts = Counter(y) # conta as ocorrências de cada rótulo\n",
    "    probabilities = [count / len(y) for count in counts.values()] # calcula as probabilidades\n",
    "    return -sum(p * np.log2(p) for p in probabilities if p > 0) # calcula a entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `information_gain` calcula e retorna o ganho de informação ao dividir X e y pela feature especificada. Tem como parâmetros:\n",
    "- `X`: DataFrame de atributos;\n",
    "- `y`: Série de rótulos/classes;\n",
    "- `feature`: nome da coluna de X a avaliar.\n",
    "Este valor pode ser, então, calculado pela fórmula:\n",
    "$$ IG = H(y) - \\sum_{j} \\frac{|S_j|}{|S|} \\cdot H(S_j) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X, y, feature):\n",
    "    values = X[feature].unique() # obtém os valores únicos da feature\n",
    "    weighted_entropy = 0 # inicializa a entropia ponderada\n",
    "\n",
    "    for v in values:\n",
    "        subset_y = y[X[feature] == v] # obtém os rótulos correspondentes\n",
    "        weighted_entropy += (len(subset_y) / len(y)) * entropy(subset_y) # calcula a entropia ponderada\n",
    "\n",
    "    return entropy(y) - weighted_entropy # calcula o ganho de informação (diferença entre a entropia original e a ponderada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principal função para a criação de uma árvore de decisão é o algoritmo `id3` (Iterative Dichotomiser 3), que retorna o nó raiz da árvore de decisão. Tem como parâmetros:\n",
    "- `X`: Dataframe de atributos;\n",
    "- `y`: Série de rótulos/classes correspondente;\n",
    "- `features`: Lista de colunas ainda disponíveis para divisão;\n",
    "- `depth`: Profundidade atual da árvore;\n",
    "- `max_depth`: Profundidade máxima permitida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(X, y, features, depth=0, max_depth=15):\n",
    "    # critérios de paragem: pureza, sem features ou profundidade máxima\n",
    "    # se o tamanho de y for igual a 1, ou se não houver mais features, ou se a profundidade máxima for atingida\n",
    "    if len(set(y)) == 1 or len(features) == 0 or depth == max_depth:\n",
    "        return Node(label=y.iloc[0]) # retorna o rótulo mais comum\n",
    "    \n",
    "    if len(features) == 0: # se não houver mais features\n",
    "        most_common_label = y.mode()[0] # o rótulo mais comum\n",
    "        return Node(label=most_common_label) # retorna o rótulo mais comum\n",
    "    #escolha de melhor feature\n",
    "    gains = [information_gain(X, y, f) for f in features] # calcula o ganho de informação para cada feature\n",
    "    best_feature = features[np.argmax(gains)] # índice da feature com maior ganho de informação\n",
    "\n",
    "    node = Node(feature=best_feature) # cria um nó com a feature escolhida\n",
    "    feature_values = X[best_feature].unique() # obtém os valores únicos da feature\n",
    "    #recursão para cada valor da feature escolhida\n",
    "    for value in feature_values:\n",
    "        subset_X = X[X[best_feature] == value] # obtém os exemplos correspondentes\n",
    "        subset_y = y[X[best_feature] == value] # obtém os rótulos correspondentes\n",
    "\n",
    "        if len(subset_y) == 0: # se não houver exemplos correspondentes\n",
    "            # nenhum exemplo com esse valor\n",
    "            most_common_label = y.mode()[0] # o rótulo mais comum\n",
    "            child = Node(label=most_common_label) \n",
    "        else:\n",
    "            #continua a recursão sem a feature escolhida\n",
    "            remaining_features = [f for f in features if f != best_feature] # features restantes\n",
    "            child = id3(subset_X, subset_y, remaining_features, depth+1, max_depth) # recursão\n",
    "\n",
    "        node.children[value] = child   # adiciona o nó filho ao dicionario de filhos do nó pai\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `majority_vote` ocorre quando existem ramos nunca vistos durante a previsão (`predict`), fazendo assim uma votação majoritária nos descendentes. Tem como parâmetro o nó atual da árvore de decisão e retorna a classe mais comum entre os filhos, ou `None` se não houver filhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(node):\n",
    "    labels = [] # lista para armazenar os rótulos\n",
    "    def collect_labels(subnode): # função recursiva para coletar rótulos\n",
    "        if subnode.label is not None: # se o nó tiver rótulo\n",
    "            labels.append(subnode.label) # adiciona o rótulo à lista\n",
    "        else:\n",
    "            for child in subnode.children.values(): # percorre os filhos\n",
    "                collect_labels(child) # chama a função recursiva\n",
    "    collect_labels(node) # coleta os rótulos\n",
    "    if labels:\n",
    "        return Counter(labels).most_common(1)[0][0] # retorna o rótulo mais comum\n",
    "    else:\n",
    "        return None # retorna None se não houver rótulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, a função `predict` prediz a classe de um exemplo usando a árvore de decisão. Tem como parâmetros:\n",
    "- `tree`: o nó raiz da árvore;\n",
    "- `sample`: a classe prevista, ou `None` se não houver previsão.\n",
    "\n",
    "Retorna a `sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    while tree.label is None: # enquanto o nó não tiver rótulo\n",
    "        value = sample.get(tree.feature) # obtém o valor da feature\n",
    "        if value in tree.children: # se o valor estiver nos filhos\n",
    "            tree = tree.children[value] # move para o nó filho correspondente\n",
    "        else:\n",
    "            # Valor nunca visto — retorna o valor de maior ocorrência entre os filhos\n",
    "            # ou uma jogada aleatória segura\n",
    "            if tree.children:\n",
    "                return majority_vote(tree) # retorna o rótulo mais comum entre os filhos\n",
    "            else:\n",
    "                return None\n",
    "    return tree.label # retorna o rótulo do nó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a implementação das funções, segue-se a criação da árvore. \n",
    "Começa-se por carregar os dados discretizados do dataset gerado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados discretizados\n",
    "data = pd.read_csv(\"mcts_dataset.csv\") # Carrega o dataset\n",
    "X = data.iloc[:, :-1] # separa as features\n",
    "y = data.iloc[:, -1] # separa o rótulo\n",
    "features = X.columns.tolist() # lista de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, treina-se (cria-se) a árvore de decisão usando a função `id3` e testa-se a mesma com a função `predict`, calculando a acurácia desse teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina a árvore de decisão\n",
    "tree = id3(X, y, features)\n",
    "\n",
    "# Testa a árvore de decisão\n",
    "sample = X.iloc[0].to_dict()  # primeira linha como dict\n",
    "predicted_label = predict(tree, sample) # previsão\n",
    "actual_label = y.iloc[0] # rótulo real\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    sample = X.iloc[i].to_dict() # primeira linha como dict\n",
    "    prediction = predict(tree, sample) # previsão\n",
    "    if prediction == y.iloc[i]: # se a previsão for correta\n",
    "        correct += 1 # incrementa o contador\n",
    "\n",
    "accuracy = correct / len(X) # calcula a acurácia\n",
    "# print(f\"Accuracy on training data: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, exporta-se a árvore de decisão, usando a biblioteca `pickle`, para ser usada mais tarde no ficheiro `game.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta a árvore de decisão\n",
    "with open(\"decision_tree.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tree, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __iris_test.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from decision_tree_builder import id3, predict, Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário, inicialmente, carregar e discretizar os dados do dataset `iris.csv`. A função `discretize` discretiza uma coluna num número fixo de bins e retorna a coluna com os valores discretizados. Tem como parâmetros:\n",
    "- `col`: Coluna a discretizar;\n",
    "- `n_bins`: Nr de bins (default: 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e discretização dos dados do dataset iris.csv\n",
    "df = pd.read_csv('iris.csv')\n",
    "\n",
    "def discretize(col, n_bins=3): # discretiza a coluna : \n",
    "    # Significa que os valores contínuos de uma coluna foram convertidos em categorias (bins)\n",
    "    return pd.cut(col, bins=n_bins, labels=[f'bin{i}' for i in range(n_bins)]) # discretiza a coluna em n_bins categorias\n",
    "\n",
    "# Discretiza todas as colunas, exceto a última (rótulo)\n",
    "for col in df.columns[:-1]:\n",
    "    df[col] = discretize(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, são preparados os atributos e rótulos, tal como a divisão dos valores em treino e teste (70% de treino e 30% de teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação de atributos e rótulos\n",
    "X = df.iloc[:, :-1] # separa as features\n",
    "y = df.iloc[:, -1] #    separa o rótulo\n",
    "features = X.columns.tolist() # lista de features\n",
    "\n",
    "# Divisão em treino e teste (70% treino, 30% teste)\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True) # embaralha o dataframe\n",
    "split_idx = int(len(df_shuffled) * 0.7) # índice de divisão \n",
    "train = df_shuffled.iloc[:split_idx].reset_index(drop=True) # treino\n",
    "test = df_shuffled.iloc[split_idx:].reset_index(drop=True) # teste\n",
    "\n",
    "X_train, y_train = train.iloc[:, :-1], train.iloc[:, -1] # separa as features\n",
    "X_test, y_test = test.iloc[:, :-1], test.iloc[:, -1] # separa o rótulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com eses valores, podemos treinar a árvore de decisão, com a função `id3` e exportá-la, caso seja necessário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino da árvore de decisão\n",
    "tree = id3(X_train, y_train, features)\n",
    "\n",
    "# Serialização da árvore de decisão com pickle\n",
    "with open('iris_tree.pkl', 'wb') as f:\n",
    "    pickle.dump(tree, f)\n",
    "print(\"Decision tree serialized to iris_tree.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, a função `print_tree` imprime a árvore de decisão de forma recursiva e tem como parâmetros:\n",
    "- `node` (Nó): nó atual da árvore de decisão;\n",
    "- `depth`: profundidade atual da árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para imprimir a árvore de decisão\n",
    "def print_tree(node: Node, depth=0):\n",
    "    indent = '  ' * depth # indentação para cada nível\n",
    "    if node.label is not None: # se o nó tiver rótulo\n",
    "        print(f\"{indent}→ Label: {node.label}\") ## imprime o rótulo\n",
    "    else:\n",
    "        # imprime a feature e os filhos\n",
    "        feat_name = features[node.feature] if isinstance(node.feature, int) else node.feature\n",
    "        print(f\"{indent}Feature: {feat_name}\")\n",
    "        for value, child in node.children.items():\n",
    "            print(f\"{indent}  If == {value}:\")\n",
    "            print_tree(child, depth+2) # imprime a árvore recursivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, basta chamar essa função e, por fim, avaliar a acurácia do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a estrutura da árvore de decisão gerada\n",
    "print(\"\\nDecision Tree Structure:\")\n",
    "print_tree(tree)\n",
    "\n",
    "# Avalia a acurácia no conjunto de teste\n",
    "correct = 0\n",
    "for idx, row in X_test.iterrows():\n",
    "    sample = row.to_dict()\n",
    "    pred = predict(tree, sample)\n",
    "    true_label = y_test.loc[idx]\n",
    "    if pred == true_label:\n",
    "        correct += 1\n",
    "accuracy = correct / len(X_test)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integração no Jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando os códigos acima apresentados, é então possível recriar o jogo Quatro em Linha. Em baixo está o código final, que importa todos os anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __game.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connected_four import ConnectState, GameMeta  # Representa o estado do jogo e a inicialização do jogo\n",
    "from mcts import MCTS                   # Implementa o algoritmo MCTS\n",
    "import pickle # usado para manipular a árvore de decisão\n",
    "from decision_tree_builder import predict  # Importa a função de previsão da árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes `RestartGameException` e `QuitGameException` são exceções específicas para controlar o fluxo do jogo, e permitem reiniciar ou sair do mesmo de forma controlada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestartGameException(Exception): # reinicia o jogo\n",
    "    pass\n",
    "\n",
    "class QuitGameException(Exception): # encerra o jogo\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar a árvore de decisão no jogo é necessário, primeiramente, de a carregar, usando o `pickle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregamento da árvore de decisão (ficheiro .pkl)\n",
    "with open(\"decision_tree.pkl\", \"rb\") as f:\n",
    "    decision_tree = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `safe_int_input` lê inteiros de forma a tratar de inputs diferentes como `restart` e `quit`, ou erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê inteiros com tratamento para \"restart\" e \"quit\"\n",
    "def safe_int_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            value = input(prompt) # lê a entrada do usuário\n",
    "            if value.lower() == 'restart': # reinicia o jogo\n",
    "                raise RestartGameException\n",
    "            if value.lower() == 'quit': # encerra o jogo\n",
    "                raise QuitGameException\n",
    "            return int(value) # converte para inteiro\n",
    "        except ValueError: # se não for um inteiro\n",
    "            print(\"Entrada inválida. Por favor insira um número inteiro.\")\n",
    "        except EOFError: # se o arquivo de entrada estiver vazio\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `safe_move_input` lê uma jogada válida, i.e., um número de 0 a 6 para associar à coluna da jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê uma jogada válida (coluna de 0 a 6)\n",
    "def safe_move_input(state, prompt=\"Escolha uma coluna (0-6), 'restart' ou 'quit': \"):\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(prompt) # lê a entrada do usuário\n",
    "            if user_input.lower() == 'restart': # reinicia o jogo\n",
    "                raise RestartGameException\n",
    "            if user_input.lower() == 'quit': # encerra o jogo\n",
    "                raise QuitGameException\n",
    "            move = int(user_input) # converte para inteiro\n",
    "            if move in state.get_legal_moves(): # se a jogada for válida\n",
    "                return move # retorna a jogada\n",
    "            print(\"Movimento inválido. Tente novamente.\") # se a jogada não for válida\n",
    "        except ValueError: # se não for um inteiro\n",
    "            print(\"Entrada inválida. Insira um número de 0 a 6.\")\n",
    "        except EOFError: # se o arquivo de entrada estiver vazio\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `state_to_features` converte o estado de jogo em features, ou seja, transforma o estado do tabuleiro num dicionário de atributos para alimentar a árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_features(state):\n",
    "    # Assumindo que o estado tem uma representação interna `board`\n",
    "    # e que a árvore foi treinada com features nomeadas como pos_0, pos_1, ..., pos_41\n",
    "    features = {}\n",
    "    for i in range(6):  # 6 linhas\n",
    "        for j in range(7):  # 7 colunas\n",
    "            index = i * 7 + j # índice linear para 2D\n",
    "            features[f\"s{index}\"] = state.board[i][j] # valor da célula (0, 1 ou 2)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida temos as funções de jogo. Existem 4 modos de jogo:\n",
    "- Jogador contra Jogador: tem como função `play_player_vs_player` e parâmetro o jogador inicial;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_player_vs_player(starting_player):\n",
    "    state = ConnectState() # inicializa o estado do jogo\n",
    "    state.to_play = starting_player # jogador inicial\n",
    "    while not state.game_over(): # enquanto o jogo não terminar\n",
    "        state.print() # imprime o tabuleiro\n",
    "        print(f\"Vez de {'X' if state.to_play==1 else 'O'}\") # jogador atual\n",
    "        move = safe_move_input(state) # lê a jogada do jogador\n",
    "        state.move(move) # aplica a jogada\n",
    "    state.print() # imprime o tabuleiro final\n",
    "    return state.get_outcome() # resultado do jogo (vencedor ou empate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jogador contra MCTS: tem como função `play_player_vs_ai` e parâmetros a peça do jogador (`player_piece`) e o jogador inicial (`first`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_player_vs_ai(player_piece, first):\n",
    "    state = ConnectState() # inicializa o estado do jogo\n",
    "    ai_piece = 2 if player_piece == 1 else 1 # jogador adversário (MCTS)\n",
    "    mcts = MCTS(state) # inicializa o MCTS\n",
    "    if first == 'ai': # se o MCTS for o primeiro a jogar\n",
    "        state.to_play = ai_piece\n",
    "        state.print()\n",
    "        print(\"MCTS a começar...\")\n",
    "        mcts.search(10) # tempo de execução inicial\n",
    "        mv = mcts.best_move() # jogada escolhida pelo MCTS\n",
    "        print(f\"MCTS ({'X' if ai_piece==1 else 'O'}) escolheu: {mv}\")\n",
    "        state.move(mv) # aplica a jogada\n",
    "        mcts.move(mv) # atualiza o MCTS\n",
    "    else:\n",
    "        state.to_play = player_piece # jogador humano\n",
    "    while not state.game_over():\n",
    "        state.print()\n",
    "        if state.to_play == player_piece: # jogador humano\n",
    "            mv = safe_move_input(state) # lê a jogada do jogador\n",
    "            state.move(mv) # aplica a jogada\n",
    "            mcts.move(mv) # atualiza o MCTS\n",
    "        else:\n",
    "            print(\"MCTS a pensar...\")\n",
    "            mcts.search(5)\n",
    "            mv = mcts.best_move()\n",
    "            print(f\"MCTS ({'X' if ai_piece==1 else 'O'}) escolheu: {mv}\")\n",
    "            state.move(mv)\n",
    "            mcts.move(mv)\n",
    "    state.print()\n",
    "    return state.get_outcome() # resultado do jogo (vencedor ou empate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jogador contra Árvore, de função `play_player_vs_tree` e parâmetros a peça do jogador (`player_piece`), o jogador inicial (`first`) e a árvore de decisão carregada no início do jogo (`tree`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_player_vs_tree(player_piece, first, tree):\n",
    "    state = ConnectState() # inicializa o estado do jogo\n",
    "    tree_piece = 2 if player_piece == 1 else 1 # jogador adversário (árvore)\n",
    "\n",
    "    if first == 'tree': # se a árvore for o primeiro a jogar\n",
    "        state.to_play = tree_piece \n",
    "        state.print()\n",
    "        features = state_to_features(state) # converte o estado para features\n",
    "        mv = predict(tree, features) # jogada escolhida pela árvore (previsão)\n",
    "        print(f\"Árvore ({'X' if tree_piece==1 else 'O'}) escolheu: {mv}\")\n",
    "        state.move(mv) # aplica a jogada\n",
    "    else:\n",
    "        state.to_play = player_piece # jogador humano\n",
    "\n",
    "    while not state.game_over():\n",
    "        state.print()\n",
    "        if state.to_play == player_piece: # jogador humano\n",
    "            mv = safe_move_input(state) # lê a jogada do jogador\n",
    "        else:\n",
    "            print(\"Árvore a pensar...\")\n",
    "            features = state_to_features(state)\n",
    "            mv = predict(tree, features)\n",
    "            print(f\"Árvore ({'X' if tree_piece==1 else 'O'}) escolheu: {mv}\")\n",
    "        state.move(mv)\n",
    "\n",
    "    state.print()\n",
    "    return state.get_outcome() # resultado do jogo (vencedor ou empate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MCTS contra Árvore, de função `play_ai_vs_tree` e parâmetros o jogador inicial (`starting_player`) e a árvore de decisão (`tree`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_ai_vs_tree(starting_player, tree):\n",
    "    state = ConnectState() # inicializa o estado do jogo\n",
    "    mcts = MCTS(state) # inicializa o MCTS\n",
    "    ai_piece = starting_player # identifica o jogador inicial\n",
    "    tree_piece = 2 if ai_piece == 1 else 1\n",
    "\n",
    "    while not state.game_over(): # enquanto o jogo não terminar\n",
    "        state.print() # imprime o tabuleiro\n",
    "        if state.to_play == ai_piece: # jogador MCTS\n",
    "            print(\"MCTS a pensar...\")\n",
    "            mcts.search(5) # tempo de execução\n",
    "            mv = mcts.best_move() # jogada escolhida pelo MCTS\n",
    "            print(f\"MCTS escolheu: {mv}\")\n",
    "        else:\n",
    "            print(\"Árvore a pensar...\") \n",
    "            features = state_to_features(state) # converte o estado para features\n",
    "            mv = predict(tree, features) # jogada escolhida pela árvore (previsão)\n",
    "            print(f\"Árvore escolheu: {mv}\")\n",
    "        state.move(mv) # aplica a jogada\n",
    "        mcts.move(mv) # atualiza o MCTS\n",
    "\n",
    "    state.print()\n",
    "    return state.get_outcome() # resultado do jogo (vencedor ou empate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após um jogo terminar, é apresentado um menu, de função `post_game_menu`, que permite ao jogador jogar novamente, mudar de modo ou sair do jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menu pós-jogo: Play Again, Change Modes, Quit\n",
    "def post_game_menu():\n",
    "    print(\"O que deseja fazer a seguir?\") \n",
    "    print(\"1: Jogar novamente\")\n",
    "    print(\"2: Mudar modo\")\n",
    "    print(\"3: Sair\")\n",
    "    choice = safe_int_input(\"Escolha: \")\n",
    "    if choice == 1:\n",
    "        return 'again'\n",
    "    if choice == 2:\n",
    "        raise RestartGameException\n",
    "    return 'quit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `main` lida com os menus iniciais, com a escolha do modo (que utiliza as funções acima), do jogador inicial e da peça do jogador. Cria um \"placar\" com o número de vitórias/derrotas caso o jogador decida fazer vários jogos seguidos no mesmo modo. Assim, durante esse tempo, o número de vitórias e derrotas é armazenado pelo sistema e impresso no terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco principal\n",
    "\n",
    "def main():\n",
    "    x_wins = o_wins = draws = 0 # contadores de vitórias e empates\n",
    "    try:\n",
    "        while True:\n",
    "            print(\"1: Jogador vs Jogador\\n2: Jogador vs MCTS\\n3: Jogador vs Árvore\\n4: MCTS vs Árvore\")\n",
    "            mode = safe_int_input(\"Modo: \")\n",
    "            # Definições iniciais do modo\n",
    "            if mode == 1: # Jogador vs Jogador\n",
    "                print(\"Quem começa? \\n1: X  \\n2: O\") # jogador X ou O\n",
    "                first = 1 if safe_int_input(\"Escolha: \")==1 else 2\n",
    "                while True:\n",
    "                    outcome = play_player_vs_player(first) # resultado do jogo\n",
    "                    if outcome == 1: x_wins += 1 # jogador X ganhou\n",
    "                    elif outcome == 2: o_wins += 1  # jogador O ganhou\n",
    "                    else: draws += 1 # empate\n",
    "                    print(\n",
    "                        f\"Placar: (X) {x_wins} - {o_wins} (O) (Empates: {draws})\"\n",
    "                        ) # imprime o placar\n",
    "                    action = post_game_menu() # menu pós-jogo\n",
    "                    if action == 'again': # jogar novamente\n",
    "                        continue\n",
    "                    elif action == 'quit': # sair\n",
    "                        raise QuitGameException\n",
    "            elif mode == 2: # Jogador vs MCTS\n",
    "                 # jogador humano ou MCTS\n",
    "                print(\"Quem começa? \\n1: Jogador  \\n2: MCTS\")\n",
    "                first = 'player' if safe_int_input(\"Escolha: \") == 1 else 'ai'\n",
    "                print(\"Que peça prefere? \\n1: X  \\n2: O\") # jogador X ou O\n",
    "                player_piece = 1 if safe_int_input(\"Escolha: \") == 1 else 2\n",
    "                mcts_piece = 3 - player_piece # jogador adversário (MCTS)\n",
    "\n",
    "                while True:\n",
    "                    outcome = play_player_vs_ai(\n",
    "                        player_piece, first) # resultado do jogo\n",
    "                    # se outcome == player_piece → jogador humano ganhou\n",
    "                    if outcome == player_piece:\n",
    "                        if player_piece == 1: # jogador X ganhou\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    elif outcome == mcts_piece: # MCTS ganhou\n",
    "                        # MCTS ganhou\n",
    "                        if mcts_piece == 1:\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    else:\n",
    "                        draws += 1 # empate\n",
    "\n",
    "                    print(\n",
    "                        f\"Placar: (X) {x_wins} - {o_wins} (O) (Empates: {draws})\"\n",
    "                        )\n",
    "                    action = post_game_menu()\n",
    "                    if action == 'again':\n",
    "                        continue\n",
    "                    elif action == 'quit':\n",
    "                        raise QuitGameException\n",
    "\n",
    "            elif mode == 3: # Jogador vs Árvore\n",
    "                 # jogador humano ou árvore\n",
    "                print(\"Quem começa? \\n1: Jogador  \\n2: Árvore\")\n",
    "                first = 'player' if safe_int_input(\"Escolha: \") == 1 else 'tree'\n",
    "                print(\"Que peça prefere? \\n1: X  \\n2: O\") # jogador X ou O\n",
    "                player_piece = 1 if safe_int_input(\"Escolha: \") == 1 else 2\n",
    "                tree_piece = 3 - player_piece\n",
    "\n",
    "                while True:\n",
    "                    outcome = play_player_vs_tree(\n",
    "                        player_piece, first, decision_tree)\n",
    "                    if outcome == player_piece: # jogador humano ganhou\n",
    "                        if player_piece == 1:\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    elif outcome == tree_piece: # árvore ganhou\n",
    "                        if tree_piece == 1:\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    else:\n",
    "                        draws += 1 # empate\n",
    "\n",
    "                    print(\n",
    "                        f\"Placar: (X) {x_wins} - {o_wins} (O) (Empates: {draws})\"\n",
    "                        )\n",
    "                    action = post_game_menu()\n",
    "                    if action == 'again':\n",
    "                        continue\n",
    "                    elif action == 'quit':\n",
    "                        raise QuitGameException\n",
    "         \n",
    "            elif mode == 4: # MCTS vs Árvore\n",
    "                # jogador MCTS ou árvore\n",
    "                print(\"Quem começa? \\n1: MCTS  \\n2: Árvore\") \n",
    "                mcts_piece = 1 if safe_int_input(\"Escolha: \") == 1 else 2\n",
    "                tree_piece = 3 - mcts_piece\n",
    "\n",
    "                while True:\n",
    "                    outcome = play_ai_vs_tree(\n",
    "                        mcts_piece, decision_tree)\n",
    "                    if outcome == mcts_piece: \n",
    "                        # MCTS ganhou\n",
    "                        if mcts_piece == 1:\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    elif outcome == tree_piece:\n",
    "                        # Árvore ganhou\n",
    "                        if tree_piece == 1:\n",
    "                            x_wins += 1\n",
    "                        else:\n",
    "                            o_wins += 1\n",
    "                    else:\n",
    "                        draws += 1 # empate\n",
    "\n",
    "                    print(\n",
    "                        f\"Placar: (X) {x_wins} - {o_wins} (O) (Empates: {draws})\"\n",
    "                        )\n",
    "                    action = post_game_menu()\n",
    "                    if action == 'again':\n",
    "                        continue\n",
    "                    elif action == 'quit':\n",
    "                        raise QuitGameException\n",
    "            else:\n",
    "                # se o modo não for válido\n",
    "                print(\"Modo inválido.\") \n",
    "    except RestartGameException: \n",
    "        # reinicia o jogo\n",
    "        print(\"Mudando modo...\")\n",
    "        main()\n",
    "    except QuitGameException: \n",
    "        # encerra o jogo\n",
    "        print(\"Programa encerrado.\")\n",
    "    except EOFError:\n",
    "    # se o arquivo de entrada estiver vazio\n",
    "        print(\"Entrada finalizada.\") \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() # executa o jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta secção, apresentamos os resultados numéricos e visuais obtidos a partir das simulações de Connect Four e do teste com o conjunto Iris.  \n",
    "Mostraremos métricas quantitativas, detalhes de partidas de exemplo (“uso ao vivo”) e visualizações da árvore de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Runs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1. Jogador vs. MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Jogador vs. MCTS](content/jogadorVSMCTS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jogador Inicial: Humano.\n",
    "Peça Inicial: Vermelho.\n",
    "Peça de MCTS: Amarelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Nr de Jogada | Análise |\n",
    "| ------------ | ------- |\n",
    "| Jogada 3 | Exploração de ambos os jogadores. |\n",
    "| Jogada 6 | Possível ataque na diagonal do Jogador Humano. |\n",
    "| Jogada 9 | Continuação de ataque do Humano. |\n",
    "| Jogada 12 | Ataque de Amarelo e bloqueio de Humano. Possível ataque na diagonal de ambos os jogadores. |\n",
    "| Jogada 15 | Ataque perigoso de Humano na diagonal. |\n",
    "| Jogada 18 | Bloqueio da diagonal pelo MCTS. |\n",
    "| Jogada 21 | Ataque na diagonal de MCTS bloqueado por Humano. Ataque perigoso de Humani na diagonal. Possível ataque duplo na horizontal e vertical de MCTS. |\n",
    "| Jogada 24 | Ataque na horizontal de MCTS e seu bloqueio. Estratégia de MCTS ataca na horizontal. Vitória de MCTS. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2. Jogador vs. Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Jogador vs. Árvore de Decisão](content/mosaic_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jogador Inicial: Humano. \n",
    "Peça Inicial: Vermelho.\n",
    "Peça da Árvore de Decisão: Amarelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Nr de Jogada | Análise |\n",
    "| ------------ | ------- |\n",
    "| Jogada 3 | Exploração do tabuleiro por ambos os jogadores. |\n",
    "| Jogada 6 | Ataque horizontal de Humano bloqueado pela Árvore de Decisão. |\n",
    "| Jogada 9 | Ataque vertical de Árvore de Decisão bloqueado por Humano. |\n",
    "| Jogada 12 | Possível ataque na diagonal de Humano bloqueado por Árvore. Ataque na vertical de Árvore. |\n",
    "| Jogada 15 | Ataque na diagonal de Humano bloqueado por Árvore. Ataque na vertical de Humano. |\n",
    "| Jogada 17 | Falha na defesa de ataque de Humano. Vitória de Humano. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3. MCTS vs. Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MCTS vs Árvore de Decisão](content/mosaic_mcts_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jogador Inicial: MCTS. \n",
    "Peça Inicial: Vermelho.\n",
    "Peça Árvore de Decisão: Amarelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Nr de Jogada | Análise |\n",
    "| ------------ | ------- |\n",
    "| Jogada 3 | Formação de ataque na vertical de MCTS. |\n",
    "| Jogada 6 | Bloqueio de potencial ataque por ID3. Formação de ataque na vertical de ID3. |\n",
    "| Jogada 9 | Formação de ataque na vertical de MCTS. |\n",
    "| Jogada 12 | Formação de ataque na vertical de ID3. |\n",
    "| Jogada 15 | Ataque na vertical da árvore de decisão. Falha na defesa de ataque de MCTS. Vitória de MCTS. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussão dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Desempenho do MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho do algoritmo Monte Carlo Tree Search pode ser avaliado sob três aspetos principais, resumidos na seguinte tabela: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variáveis | Definição | Resultado | Análise | Possíveis melhorias |\n",
    "| --------- | --------- | --------- | ------- | ------------------- |\n",
    "| **Rollouts por segundo** | **Número de simulações completas** (“playouts”) que o MCTS executa por segundo de CPU. Cada rollout percorre Seleção → Expansão → Simulação → Retropropagação até o fim do jogo. Mais rollouts geralmente significam melhor estimativa de valor de cada movimento, pois exploram mais cenários futuros. | ≈ 77 rollouts/s | Adequado para análises táticas profundas, mas talvez **insuficiente** para cenários com centenas de partidas simultâneas. | Uma mitigação seria paralelizar simulações ou usar heurísticas de poda (e.g. uct-random) pode elevar essa taxa. |\n",
    "| **Tempo médio por decisão** | **Tempo de CPU gasto em média para escolher uma jogada**. Se usarmos um limite fixo de X segundos em cada iteração de search, este será próximo de X, mas pequenas variações ocorrem por conta do overhead de Python e estruturas de dados. Ajuda a entender se o algoritmo é viável em tempo real. Por exemplo, para um agente adversário rápido, 3 s por jogada pode ser aceitável; para um servidor de partidas online com mil partidas simultâneas, talvez não. | ≈ 3,01 s | Viável em aplicações offline ou semi‑realtime, mas lento para sistemas interativos. | Uma alternativa seria limitar o número de rollouts ou implementar uma versão incremental do MCTS. |\n",
    "| **Win-Rate contra Árvore de Decisão** | Proporção de partidas em que o MCTS sai **vencedor** contra a árvore de decisão. | 100% | Mostra que, mesmo com latência (tempo entre comando e execução), o MCTS produz jogadas consistentemente superiores em cenários adversariais estáticos. | Nada a melhorar neste aspeto. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Frequência de Jogadas do MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Frequência de Jogadas do MCTS](content/numeroJogadas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figura 1: Frequência de cada jogada no dataset mcts_dataset.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- É possível ver que o MCTS tende a escolher muito mais as colunas centrais do tabuleiro. Em particular, a coluna 3 (o centro absoluto) responde por cerca de 25–30 % de todas as jogadas geradas, seguida pelas colunas 2 e 4 com ~15–20 % cada. Já as colunas de borda (0 e 6) aparecem em menos de 5 % dos exemplos.\n",
    "\n",
    "- Reflete uma estratégia clássica de Connect-Four: controlar o centro maximiza o número de linhas de quatro possíveis e permite maior flexibilidade tática. \n",
    "\n",
    "- No entanto, esse desequilíbrio no dataset pode causar um viés no modelo ID3, que vai aprender muito bem a classe “3” mas terá menos amostras para diferenciar adequadamente as jogadas de borda.\n",
    "\n",
    "- Como consequência, a acurácia do ID3 estará inflada se medida apenas globalmente (pois grande parte das previsões recai sobre as colunas centrais).\n",
    "\n",
    "- Para mitigar essa assimetria, poderíamos aplicar técnicas de re-amostragem (undersampling das classes centrais ou oversampling das extremas) ou class weighting ao treinar a árvore, de modo a equilibrar melhor o aprendizado entre todos os tipos de jogada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Impacto de alpha "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impacto de alpha](content/impactoAlpha.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figura 2: Impacto de alpha na taxa de vitória e tempo médio de decisão.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| α = 0.1 | α = 0.5 (ponto ótimo) | α = 1.0 |\n",
    "| ------- | ------- | ------- |\n",
    "|Mais \"exploitation\" na fórmula UCT (α baixo) dá quase o mesmo “sucesso” (97 %) mas leva um pouco mais de tempo (1.90 s).|Maior taxa de vitória (99 %) e menor tempo por jogada (~1.86 s).|Total foco em \"exploration\" (α alto) aumenta a velocidade (2.02 s) e faz a taxa de vitória cair para 97 %.|\n",
    "|Provavelmente o agente está a desperdiçar algumas simulações em ramos menos promissores.|É aí que a exploração vs. exploit está mais equilibrada para o setup usado: explora o suficiente para ver novas jogadas, mas sem dispersar demasiado o esforço de simulação.|Quando exploras demais sem peso para a parte de “exploitation”, a árvore não aprofunda rápido nas jogadas que já sabem ser boas.|\n",
    "\n",
    "Conclui-se que `α ≃ 0.5` parece ser o **“sweet spot”** para o MCTS face ao adversário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4. Forças e limitações do algoritmo Monte Carlo Tree Search (MCTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Vantagens`: adaptável a diferentes jogos, bom trade‑off exploit vs explore; não requer função de avaliação manual;\n",
    "\n",
    "- `Limitações`: alto custo computacional, potencial para heurísticas pobres em horizontes de busca muito longos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5. Desempenho da Árvore de Decisão com o algoritmo ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desempenho da árvore de decisão pode ser avaliado a partir do dataset gerado, e, consequentemente, a partir de algumas variáveis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variável                    | Definição                                                                                                               | Resultado    | Análise                                                                                                                                                             | Possíveis melhorias                                                                                                                               |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------|--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|**Nº de nós da árvore**         | Número total de nós (internos + folhas) gerados pelo algoritmo ID3 durante o treino.                                    | 16 061       | Árvores muito grandes tendem a captar ruído; um nó por registo indica forte complexidade e risco elevado de overfitting.                                              | Introduzir um parâmetro de **min_samples_split** mais alto ou poda pós-treino para reduzir nós supérfluos.                                         |\n",
    "| **Profundidade máxima**         | Distância (em níveis) entre a raiz e a folha mais profunda.                                                              | 16           | Profundidade elevada dificulta interpretabilidade e sugere divisão excessiva; a árvore faz decisões muito específicas.                                                | Limitar **max_depth** (p. ex. a 5–8 níveis) para forçar divisões mais gerais e evitar percursos demasiado longos.                                  |\n",
    "| **Precisão treino**             | Percentagem de exemplos do conjunto de treino classificados corretamente pela árvore.                                   | 73,03 %      | Valor moderado em treino revela que, mesmo nos dados vistos, o modelo não encaixa perfeitamente — possivelmente devido a ruído ou muitos atributos irrelevantes.      | Fazer **feature selection** (e.g. variância mínima, informação mútua) para retirar atributos pouco informativos antes do treino.                     |\n",
    "| **Precisão teste**              | Percentagem de exemplos do conjunto de teste classificados corretamente.                                                | 27,78 %      | Queda drástica face ao treino indica fraca capacidade de generalização: o modelo não aprendeu padrões úteis para dados novos.                                         | Usar **validação cruzada** para selecionar hiperparâmetros (profundidade, limiares de split) e melhorar robustez do modelo.                         |\n",
    "| **Tempo médio inferência**      | Tempo de CPU médio gasto para descer a árvore e produzir uma previsão por instância (média sobre até 100 amostras).     | ≈ 0,0000 s   | Inferência praticamente instantânea — excelente desempenho para produção — mas insuficiente para compensar a baixa qualidade das previsões.                           | Manter performance, mas considerar **ensembles** (Random Forest) para melhorar precisão sem sacrificar muito a velocidade de inferência.             |\n",
    "| **Atributos usados (méd.)**     | Número médio de divisões (features) examinadas no caminho da raiz até à folha para cada instância de teste.             | 12,60        | Percursos longos (quase a profundidade máxima) confirmam que o modelo faz muitas divisões antes de prever, refletindo a alta complexidade da árvore.                   | Aplicar **poda** baseada em complexidade ou em ganho mínimo de informação para encurtar caminhos e simplificar as regras de decisão.                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6. Relação entre acurácia, profundidade e tempo de previsão da árvore usando o algoritmo ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Acurácia x Profundidade x Tempo de Previsão](content/acuráciaxprofundidadextempo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figura 3. Acurácia da árvore ID3 em função da profundidade e do tempo de previsão.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Tendência geral de melhoria:` A acurácia sobe de 15,23 % (depth 2) para 22,23 % (depth 10), e o tempo médio de previsão mantém-se em ≈ 0,004 ms até profundidade 8, saltando para 0,007 ms em depth 10. Isso mostra que árvores mais profundas capturam mais padrões do dataset, elevando a precisão ao mesmo tempo que aumentam o custo computacional em níveis mais altos de profundidade.\n",
    "- `Baixa performance em profundidades rasas (2–4):` Em depth 2 e 4, a acurácia é apenas ≈ 15 %, claro sintoma de underfitting — o modelo é demasiado simples para as relações do conjunto. O tempo médio de previsão é mínimo e idêntico nesses dois casos (≈ 0,004 ms), refletindo a estrutura pouco profunda.\n",
    "- `Grande salto de 4 para 6:` Passar de depth 4 (15,67 %) para 6 (19,10 %) traz um ganho de ≈ 3,4 %, indicando que a árvore começa a capturar interações antes ignoradas. O tempo médio mantém-se em ≈ 0,004 ms, sugerindo que até essa profundidade a complexidade extra não impacta significativamente a latência de inferência.\n",
    "- `Possível ponto de equilíbrio (“sweet spot”):` Embora a acurácia máxima ocorra em depth 10, o equilíbrio entre ganho de precisão e consistência do tempo de predição pode favorecer profundidades entre 6 e 8.\n",
    "- `Melhor profundidade (maior acurácia):` Depth 10: acurácia = 22,23 %, tempo médio ≈ 0,007 ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7. Forças e limitações do algoritmo Iterative Dichotomiser 3 (ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Vantagens`: interpretabilidade, rapidez de predição;\n",
    "\n",
    "- `Limitações`: baixa robustez em cenários de alta dimensionalidade / características contínuas sem discretização cuidadosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.8. Comparação Geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Critério          | ID3 (Árvore de Decisão) | MCTS                 |\n",
    "| ----------------- | ----------------------- | -------------------- |\n",
    "| Tipo de algoritmo | Supervisionado (aprende com os dados)| Não supervisionado (baseado em simulação) |   \n",
    "| Treino            | Necessita de dataset    | Nada                 |\n",
    "| Capacidade de generalização     | Limitada aos padrões nos dados| Explora os estados dinamicamente|\n",
    "| Desempenho tático | Previsível e frágil     | Adapta-se            |\n",
    "| Velocidade de Decisão   | Muito rápida (árvore já construída) | Mais lenta (requer simulações)|\n",
    "| Complexidade Computacional    | Baixa depois de treinada       | Alta (depende de nr de simulações)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Cenários simples (board estável, poucos movimentos)`: ID3 pode competir razoavelmente bem;\n",
    "\n",
    "- `Cenários complexos (alto branching factor)`: MCTS tende a superar.\n",
    "\n",
    "Conclui-se que:\n",
    "- O ID3 é útil para demonstrar como a IA pode tomar decisões com base em exemplos passados, mas não reage bem a situações fora do padrão;\n",
    "- O MCTS é mais robusto, adaptável e inteligente em tempo real, especialmente quando configurado com um número razoável de simulações e bom ajuste do coeficiente de exploração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.9. Sugestões de Extensões Futuras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementar poda em ID3 (e.g. reduced error pruning);\n",
    "\n",
    "- Comparar com outros algoritmos de decisão (e.g. Random Forest, XGBoost);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trabalho, explorámos duas abordagens distintas de Inteligência Artificial aplicadas ao jogo Connect Four: Monte Carlo Tree Search (MCTS) e Árvores de Decisão (ID3). \n",
    "\n",
    "O MCTS demonstrou ser significativamente mais eficaz. Ao simular milhares de partidas possíveis antes de tomar decisões, esta abordagem conseguiu adaptar-se melhor ao adversário e ao estado atual do jogo. O uso de parâmetros como o número de simulações e o coeficiente de exploração (com ajuste via `alpha`) mostrou-se crucial para alcançar um bom desempenho.\n",
    "\n",
    "Por outro lado, a árvore de decisão, treinada com exemplos de jogadas rotuladas, revelou-se uma solução rápida e compreensível, ideal para situações em que há padrões bem definidos. No entanto, a sua limitação torna-se evidente em jogos com muitas possibilidades ou situações novas não presentes no conjunto de treino.\n",
    "\n",
    "Concluímos que, embora o ID3 seja uma boa introdução a modelos supervisionados, o MCTS é a abordagem mais recomendada para jogos com alto número de estados e onde a tomada de decisão precisa ser dinâmica e exploratória. O projeto mostrou na prática como diferentes paradigmas de IA têm pontos fortes em contextos distintos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qi Wang’s Blog! (2022). Connect 4 with Monte Carlo Tree Search. [online] Available at: https://www.harrycodes.com/blog/monte-carlo-tree-search;\n",
    "\n",
    "- matant (2020). Monte Carlo Tree Search - ConnectX. [online] Kaggle.com. Available at: https://www.kaggle.com/code/matant/monte-carlo-tree-search-connectx;\n",
    "‌\n",
    "- ‌OpenAI (2025). ChatGPT. [online] chatgpt.com. Available at: https://chatgpt.com;\n",
    "‌\n",
    "- GeeksforGeeks. (2024). Iterative Dichotomiser 3 (ID3) Algorithm From Scratch. [online] Available at: https://www.geeksforgeeks.org/iterative-dichotomiser-3-id3-algorithm-from-scratch/;\n",
    "‌\n",
    "- AshirbadPradhan (2023). Decision Tree ID3 Algorithm |Machine Learning. [online] Medium. Available at: https://medium.com/@ashirbadpradhan8115/decision-tree-id3-algorithm-machine-learning-4120d8ba013b.\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
